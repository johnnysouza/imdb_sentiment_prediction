{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76b7aa5",
   "metadata": {},
   "source": [
    "### Classificação de textos para análise de sentimentos\n",
    "\n",
    "Base de dados \n",
    "\n",
    "Istruções:\n",
    "- O objetivo deste trabalho é criar um modelo binário de aprendizado de máquina para classificação de textos. \n",
    "Para isso, será utilizado a base de dados [IMDb](http://ai.stanford.edu/~amaas/data/sentiment/), que consiste de dados textuais de críticas positivas e negativas de filmes\n",
    "- Uma vez treinado, o modelo deve ter uma função `predict` que recebe uma string como parâmetro e retorna o valor 1 ou 0, aonde 1 significa uma crítica positiva e 0 uma crítica negativa\n",
    "- O pré-processamento pode ser desenvolvidado conforme desejar (ex.: remoção de stopwords, word embedding, one-hot encoding, char encoding)\n",
    "- É preferível que seja empregado um modelo de recorrência (ex.: rnn, lstm, gru) para a etapa de classificação\n",
    "- Documente o código (explique sucintamente o que cada função faz, insira comentários em trechos de código relevantes)\n",
    "- **Atenção**: Uma vez treinado o modelo final, salve-o no diretório do seu projeto e crie uma célula ao final do notebook contendo uma função de leitura deste arquivo, juntamente com a execução da função `predict`\n",
    "\n",
    "Sugestões:\n",
    "- Explorar a base de dados nas células iniciais do notebook para ter um melhor entendimento do problema, distribuição dos dados, etc\n",
    "- Após desenvolver a estrutura de classificação, é indicado fazer uma busca de hiperparâmetros e comparar os resultados obtidos em diferentes situações\n",
    "\n",
    "Prazo de entrega:\n",
    "- 26-06-2021 às 23:59hs GMT-3\n",
    "\n",
    "Formato preferível de entrega:\n",
    "- Postar no portal Ava da disciplina o link do projeto no github (ou anexar o projeto diretamente no portal Ava)\n",
    "\n",
    "luann.porfirio@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtext\n",
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bigger-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a5bfc",
   "metadata": {},
   "source": [
    "#### Pré-processamento do dataset, tratando:\n",
    "- Remoção das tags HTML;\n",
    "- Remoção das pontuações e demais caracteres não alfa-numéricos;\n",
    "- Lematização das palavras;\n",
    "- Remoção das \"stop words\";\n",
    "- Filtro para manter apenas adjectivos, advérbios, substantivos e verbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd52b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pos_filter = ['ADJ', 'ADV', 'NOUN', 'VERB'] #adjective, adverb, noun, verd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96bc4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review: str) -> List[str]:\n",
    "    review = re.sub(\"<[^>]*>\", \"\",  review) #Remove HTML tags\n",
    "    review = re.sub(\"[^0-9a-zA-Z ]+\", \"\",  review) #Remove qualquer caracter não alfa-numérico, menos o espaço\n",
    "    processed_words = nlp(review)\n",
    "    return [word.lemma_.strip().lower() for word in processed_words if not word.is_stop and word.pos_ in pos_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb1230",
   "metadata": {},
   "source": [
    "#### Carregamento do dataset\n",
    "- Utilizando uma semente fixa para melhor reprodução dos resultados;\n",
    "- Carregamento das reviews utilizando o método de pré-processamento acima definido;\n",
    "- Leitura dos labels como valores numéricos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c95e886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "TEXT = data.Field(tokenize = process_review,\n",
    "                  include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2329bd",
   "metadata": {},
   "source": [
    "#### Divisão do dataset\n",
    "- Divisão feita para treino, desenvolvimento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e31798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, dev_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35cab048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 17500\n",
      "Dev size: 7500\n",
      "Test size: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Dev size: {len(dev_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11385338",
   "metadata": {},
   "source": [
    "#### Criação do vocabulário para treinamento, utilizando vetores pré-treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8cdf6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d231f1",
   "metadata": {},
   "source": [
    "#### Verificação das palavras mais comuns no vocabulário construído"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72658e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('movie', 34341), ('film', 31711), ('good', 13713), ('time', 10109), ('character', 9564), ('watch', 9235), ('bad', 8833), ('story', 8593), ('see', 8590), ('think', 7990), ('scene', 7162), ('s', 6853), ('look', 6645), ('great', 6617), ('know', 6456), ('people', 6367), ('go', 5924), ('play', 5828), ('way', 5813), ('come', 5707)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d6cfa",
   "metadata": {},
   "source": [
    "#### Verificação dos valores atribuídos aos labels de avaliação positiva e negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17a5b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c791cd2",
   "metadata": {},
   "source": [
    "####  Definição do tamanho dos lotes de processamento e criação dos iteradores para treino, desevolvimento e teste \n",
    "- Nos testes realizados não houve memória dedicada suficiente na GPU para treinamento do modelo, por isso foi fixado para treinar em CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48b50672",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "train_iterator, dev_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, dev_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499494a",
   "metadata": {},
   "source": [
    "#### Definição do modelo\n",
    "- Modelo LSTM bidirecional, com dropout e duas camadas;\n",
    "- Criação de word embedding para melhor representação das palavras das revisões;\n",
    "- Criada camada totalmente conectada de neurônios para receber as saída do LSTM e gerar uma saída única (que será utilizada para fazer a predição de positivo ou negativo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93be1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDB_LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, pad_idx, embedding_dim=100, n_hidden=256, n_layers=2,\n",
    "                               drop_prob=0.5, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
    "                            hidden_size=n_hidden,  \n",
    "                            num_layers=n_layers, \n",
    "                            dropout=drop_prob,\n",
    "                            bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden * 2, 1)\n",
    "      \n",
    "    \n",
    "    def forward(self, x, x_lengths): \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, x_lengths.to('cpu'))\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        hidden = self.fc(hidden)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761e635",
   "metadata": {},
   "source": [
    "#### Definição dos hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0099c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_HIDDEN = 256\n",
    "N_LAYERS = 2\n",
    "DROP_PROB = 0.5\n",
    "LEARNING_RATE = 0.0001\n",
    "N_EPOCHS = 5\n",
    "BIDIRECTIONAL = True\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57077ad",
   "metadata": {},
   "source": [
    "#### Criação do modelo\n",
    "- Definição da função de custo e do otimizador;\n",
    "- Inicialização dos pesos pré-treinados do word embedding, zerando os tokens unk e pad conforme dica enontrada online pois inicialmente eles são irrelevantes para determinação do sentimento;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbc7813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMDB_LSTM(VOCAB_SIZE,\n",
    "                  PAD_IDX,\n",
    "                  embedding_dim=EMBEDDING_DIM, \n",
    "                  n_hidden=N_HIDDEN, \n",
    "                  n_layers=N_LAYERS, \n",
    "                  drop_prob=DROP_PROB, \n",
    "                  bidirectional=BIDIRECTIONAL,\n",
    "                 ).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b26bd",
   "metadata": {},
   "source": [
    "#### Função de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c183e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        label = batch.label\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(text, text_lengths)\n",
    "        \n",
    "        loss = criterion(predictions.squeeze(1), label)\n",
    "        \n",
    "        epoch_correct += torch.sum(torch.eq(predictions.argmax(1), label))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_correct / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d38eb7",
   "metadata": {},
   "source": [
    "#### Função de validação para desenvolvimento e testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2174cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            label = batch.label\n",
    "            \n",
    "            predictions = model(text, text_lengths)\n",
    "            epoch_correct += torch.sum(torch.eq(predictions.argmax(1), label))\n",
    "        \n",
    "    return epoch_correct / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43af79",
   "metadata": {},
   "source": [
    "#### Treinamento da primeira época separadamente para avaliar condição inicial do modelo antes de seguir com o restante do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8904354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.594 | Train Acc: 32.15%\n",
      "\tDev Acc: 31.27%\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "dev_acc = evaluate(model, dev_iterator, criterion)\n",
    "\n",
    "print(f\"Epoch: {1:02}\")\n",
    "print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%\")\n",
    "print(f\"\\tDev Acc: {dev_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595cbee",
   "metadata": {},
   "source": [
    "#### Treinamento das demais época para completa 5 época de treinamento ao todo\n",
    "- Alguma coisa está impactando na não evolução da acurrácia do modelo apesar do erro diminuir com o passar do tempo, mas não houve tempo para continuar a avaliação do que estava acontecendo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d580b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02\n",
      "\tTrain Loss: 0.482 | Train Acc: 32.15%\n",
      "\tDev Acc: 31.27%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.451 | Train Acc: 32.15%\n",
      "\tDev Acc: 31.27%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.431 | Train Acc: 32.15%\n",
      "\tDev Acc: 31.27%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.413 | Train Acc: 32.15%\n",
      "\tDev Acc: 31.27%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS-1):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    dev_acc = evaluate(model, dev_iterator, criterion)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+2:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"\\tDev Acc: {dev_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0460569",
   "metadata": {},
   "source": [
    "#### Teste final do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3af0e06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 31.97%\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test Acc: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d103f",
   "metadata": {},
   "source": [
    "#### Persistência do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a4b31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'IMDB_LSTM_bidirectional.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88b7f8",
   "metadata": {},
   "source": [
    "#### Leitura do modelo treinado (necessário executar o código até antes da sessão de treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "204e6987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('IMDB_LSTM_bidirectional.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5fa04",
   "metadata": {},
   "source": [
    "#### Função de predição do sentimento para uma senteção\n",
    "- Retorna zero para sentimento negativo;\n",
    "- Retorna um para sentimento positivo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc6e90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    tensor_length = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, tensor_length))\n",
    "    return int(round(prediction.item(), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d624c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c5679ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This film is great\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
